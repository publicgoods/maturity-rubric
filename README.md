# Maturity Rubric

This repository is a shared space for conversation and collaboration to define core
standards and specifications for a rubric that can be use to evaluate and vet digital
public goods. 


## Introduction

Many digital platforms have been developed to support the Sustainable Development Goals. 
However, there are few metrics or systems defined to evaluate the maturity, quality, and
sustainability of these goods. 

This project is a cooperative effort led by [Digital Impact Alliance](https://digitalimpactalliance.org) and partners to establish a core set of categories and criteria that can be used to evaluate and 'score' digital technologies. This data will provide much needed information to help actors understand and select digital tools to support their projects and use cases. In alignment with the principle of [Reuse and Improve](https://digitalprinciples.org/principle/reuse-and-improve/) from the Principles for Digital Development, the following sources were harmonized to create the first iteration of the categories and criteria:
- [CHAOSS](https://chaoss.community/metrics/)
- [Digital Square Global Good Maturity Model](https://wiki.digitalsquare.io/index.php/What_are_Global_Goods)
- [DIAL Open Source Center Project Maturity Evaluation](https://www.osc.dial.community/maturity-model.html)
- [ClearlyDefined](https://github.com/clearlydefined/license-score/blob/master/ClearlyLicensedMetrics.md)



## Table of Contents

- [Goal](#goal)
- [Proposed Workflow](#proposed-workflow)
- [Contributing](#contributing)
- [Governance](#governamce)
- [Resources](Resources/README.md)


## Goal

The goal of this work is to define a common ontology for evaluating digital products.
This ontology will include broad categories for evaluating products and specific indicators
or data points that can be collected about a product. 


## Proposed workflow

The initial work on the maturity rubric is to define and agree on a set of categories that 
will be used for evaluating digital goods. See the [Categories](categories.md) page for 
information on that work.

The second phase of the work will be to define specific indicators for each category. 
Indicators are data points that can be collected for each product that we wish to evaluate. 
These indicators may be either quantitative or qualitative. See the [Indicators](indicators.md) 
page for more information.

Alongside the work above, we will also develop user profiles that describe different types 
of users and how they will interact with the maturity rubric. The [Users](users.md) page 
describes this work.

Finally, we will develop a process for establishing scoring systems, where a product
is assigned a specific score to indicate its maturity. The [Scoring](scoring.md) page outlines
this work.


## Contributing

We welcome contributions from individuals and organizations. See the 
[Contributing](CONTRIBUTING.md) page for more information.


## Governance

